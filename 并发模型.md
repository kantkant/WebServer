# 并发模型

程序使用Reactor模型，并使用多线程提高并发度。为避免线程频繁创建和销毁带来的开销，使用线程池，在程序的开始创建固定数量的线程。使用epoll作为IO多路复用的实现方式。

## 线程
一般而言，多线程服务器中的线程可分为以下几类：  

* IO线程(负责网络IO)
* 计算线程(负责复杂计算)
* 第三方库所用线程

因为Web静态服务器计算量较小，所以没有分配计算线程，减少跨线程分配的开销，让IO线程兼顾计算任务。每个线程一个事件循环，遵循One loop per thread。

## 并发模型
本程序使用的并发模型如下图所示：

![并发模型](https://github.com/kantkant/WebServer/blob/master/testData/model.png)

MainReactor只有一个，负责响应client的连接请求，并建立连接，它使用一个NIO Selector。在建立连接后用Round Robin的方式分配给某个SubReactor,因为涉及到跨线程任务分配，需要加锁，这里的锁由某个特定线程中的loop创建，只会被该线程和主线程竞争。

SubReactor可以有一个或者多个，每个subReactor都会在一个独立线程中运行，并且维护一个独立的NIO Selector。

当主线程把新连接分配给了某个SubReactor，该线程此时可能正阻塞在多路选择器(epoll)的等待中，怎么得知新连接的到来呢？这里使用了eventfd进行异步唤醒，线程会从epoll_wait中醒来，得到活跃事件，进行处理。

我学习了muduo库中的runInLoop和queueInLoop的设计方法，这两个方法主要用来执行用户的某个回调函数，queueInLoop是跨进程调用的精髓所在，具有极大的灵活性，我们只需要绑定好回调函数就可以了，我仿照muduo实现了这一点。

## epoll工作模式
epoll的触发模式在这里我选择了ET模式，muduo使用的是LT，这两者IO处理上有很大的不同。ET模式要比LE复杂许多，它对用户提出了更高的要求，即每次读，必须读到不能再读(出现EAGAIN)，每次写，写到不能再写(出现EAGAIN)。而LT则简单的多，可以选择也这样做，也可以为编程方便，比如每次只read一次(muduo就是这样做的，这样可以减少系统调用次数)。

## 定时器

每个SubReactor持有一个定时器，用于处理超时请求和长时间不活跃的连接。muduo中介绍了时间轮的实现和用stl里set的实现，新一版的TimerNodeList重新设计数据结构，在我当前的应用场景下实现了增删改查时间复杂度都收O(1)。
考虑当前的使用场景：在每次事件循环的开始更新所有活跃的连接的超时时间，在每次事件循环的结束删除到期的连接。
具体来说，新一版的TimerNode采用了了链式存储，使用循环链表保存所有节点。
* 在更新TimerNode时，只需要从唯一对应的channel中找到这个指针，将这个指针放入链表的末尾并更新超时时间。
* 在删除时，只需删除chanel对应的TimerNode节点。
* 添加新的节点时，直接加到队列末尾。
* 并采用惰性删除的方式，事件的超时不会唤醒线程，而是每次循环的最后进行检查，如果超时了再删，因为这里对超时的要求并不会很高，如果此时线程忙，那么检查时间队列的间隔也会短，如果不忙，也给了超时请求更长的等待时间。

## 核心结构

程序中的每一个类和结构体当然都必不可少，其中能体现并发模型和整体架构的，我认为是有两个：

* Channel类：Channel是Reactor结构中的“事件”，它自始至终都属于一个EventLoop，负责一个文件描述符的IO事件，在Channel类中保存这IO事件的类型以及对应的回调函数，当IO事件发生时，最终会调用到Channel类中的回调函数。因此，程序中所有带有读写时间的对象都会和一个Channel关联，包括loop中的eventfd，listenfd，HttpConn等。
* EventLoop：One loop per thread意味着每个线程只能有一个EventLoop对象，EventLoop即是事件循环，每次从Epoller里拿活跃事件，并给到Channel里分发处理。EventLoop中的loop函数会在最底层(Thread)中被真正调用，开始无限的循环，直到某一轮的检查到退出状态后从底层一层一层的退出。
